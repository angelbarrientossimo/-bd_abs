------------- ESPECIALIZACIÓN EN INTELIGENCIA ARTIFICIAL Y BIG DATA -------------
---------------------------------------------------------------------------------

Módulo:                     BIG DATA APLICADO

Profesor:                   Víctor J. González

Unidad de Trabajo:          UT02. HDFS. Almacenamiento distribuido

Práctica:                   PR0403: Análisis de logs con MapReduce

Resultados de aprendizaje:  RA1

## PR0403: Análisis de logs con MapReduce

Para esta práctica vamos a utilizar el dataset que puedes encontrar en Kaggle llamado Server Logs . Ahí encontrarás un dataset sintético con datos con los datos de log de un servidor Apache.

Lo primero que tendrás que hacer es conocer los datos con los que vas a trabajar, como pista, cada línea tiene este formato aproximado:

IP - - [Fecha:Hora Zona] "MÉTODO URL PROTOCOLO" Código Bytes "Referer" "User-Agent" Tiempo_Respuesta

Como consejo, crea un fichero de tamaño reducido para las pruebas ya que el fichero original es bastante grande.

Realiza las siguientes tareas utilizando MapReduce.

### 1. Estadísticas básicas

Contador de Códigos de Estado HTTP
Queremos saber cuántas peticiones resultaron exitosas (200), cuántas no encontradas (404), errores de servidor (500), etc.

Para conseguirlo, tienes que hacer lo siguiente:

Mapper:

Lee la línea.
    
Busca el código de estado (el número después de "HTTP/1.0"). En tu ejemplo son: 502, 200, 404, 304, etc.

Emite (código, 1).

Reducer: Suma los contadores.

Salida esperada: 200: 50, 404: 10, 500: 5...


```python
!hdfs dfs -mkdir /practica_log
```


```python
!hdfs dfs -put logfiles.log /practica_log
```


```python
!hdfs dfs -ls /practica_log
```

    Found 1 items
    -rw-r--r--   3 root supergroup  241981538 2025-12-16 15:24 /practica_log/logfiles.log



```python
%%writefile mapper_ejercicio_log.py
#!/usr/bin/env python3
import os
import sys

for line in sys.stdin:
    line = line.strip()


    parts = line.split(" ")

    if len(parts) > 8:
        status_code = parts[8]
        print(f"{status_code}\t1")

```

    Writing mapper_ejercicio_log.py



```python
!cat logfiles.log | python3 mapper_ejercicio_log.py | sort 
```


```python
%%writefile reducer_ejercicio_log.py
import os
import sys

current_status = None
current_count = 0

for line in sys.stdin:
    line = line.strip()

    status_code, count = line.split('\t')
    count = int(count)

    if current_status == status_code:
        current_count += count
    else:
        if current_status is not None:
            print(f"{current_status}\t{current_count}")

        current_status = status_code
        current_count = count

if current_status is not None:
    print(f"{current_status}\t{current_count}")

```

    Overwriting reducer_ejercicio_log.py



```python
!cat logfiles.log | python3 mapper_ejercicio_log.py | sort |python3 reducer_ejercicio_log.py
```

    200	142564
    303	142261
    304	143337
    403	143014
    404	142539
    500	142729
    502	143556


Ejecutamos en streaming


```python
!hdfs dfs -rmdir /log
```


```python
!hadoop jar /usr/local/hadoop/share/hadoop/tools/lib/hadoop-streaming-3.4.0.jar \
-files mapper_ejercicio_log.py,reducer_ejercicio_log.py \
-mapper "python3 mapper_ejercicio_log.py" \
-reducer "python3 reducer_ejercicio_log.py" \
-input /practica_log/logfiles.log \
-output /log

```

    packageJobJar: [/tmp/hadoop-unjar697669863971694868/] [] /tmp/streamjob3031850023655735371.jar tmpDir=null
    2025-12-16 15:42:26,860 INFO client.DefaultNoHARMFailoverProxyProvider: Connecting to ResourceManager at yarnmanager/172.19.0.6:8032
    2025-12-16 15:42:26,934 INFO client.DefaultNoHARMFailoverProxyProvider: Connecting to ResourceManager at yarnmanager/172.19.0.6:8032
    2025-12-16 15:42:27,090 INFO mapreduce.JobResourceUploader: Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/root/.staging/job_1765898224481_0007
    2025-12-16 15:42:27,345 INFO mapred.FileInputFormat: Total input files to process : 1
    2025-12-16 15:42:27,355 INFO net.NetworkTopology: Adding a new node: /default-rack/172.19.0.2:9866
    2025-12-16 15:42:27,356 INFO net.NetworkTopology: Adding a new node: /default-rack/172.19.0.4:9866
    2025-12-16 15:42:27,356 INFO net.NetworkTopology: Adding a new node: /default-rack/172.19.0.5:9866
    2025-12-16 15:42:27,402 INFO mapreduce.JobSubmitter: number of splits:2
    2025-12-16 15:42:27,492 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1765898224481_0007
    2025-12-16 15:42:27,492 INFO mapreduce.JobSubmitter: Executing with tokens: []
    2025-12-16 15:42:27,619 INFO conf.Configuration: resource-types.xml not found
    2025-12-16 15:42:27,620 INFO resource.ResourceUtils: Unable to find 'resource-types.xml'.
    2025-12-16 15:42:27,677 INFO impl.YarnClientImpl: Submitted application application_1765898224481_0007
    2025-12-16 15:42:27,703 INFO mapreduce.Job: The url to track the job: http://yarnmanager:8088/proxy/application_1765898224481_0007/
    2025-12-16 15:42:27,704 INFO mapreduce.Job: Running job: job_1765898224481_0007
    2025-12-16 15:42:31,757 INFO mapreduce.Job: Job job_1765898224481_0007 running in uber mode : false
    2025-12-16 15:42:31,758 INFO mapreduce.Job:  map 0% reduce 0%
    2025-12-16 15:42:36,812 INFO mapreduce.Job:  map 100% reduce 0%
    2025-12-16 15:42:40,832 INFO mapreduce.Job:  map 100% reduce 100%
    2025-12-16 15:42:40,850 INFO mapreduce.Job: Job job_1765898224481_0007 completed successfully
    2025-12-16 15:42:40,917 INFO mapreduce.Job: Counters: 54
    	File System Counters
    		FILE: Number of bytes read=8000006
    		FILE: Number of bytes written=16942731
    		FILE: Number of read operations=0
    		FILE: Number of large read operations=0
    		FILE: Number of write operations=0
    		HDFS: Number of bytes read=241985830
    		HDFS: Number of bytes written=77
    		HDFS: Number of read operations=11
    		HDFS: Number of large read operations=0
    		HDFS: Number of write operations=2
    		HDFS: Number of bytes read erasure-coded=0
    	Job Counters 
    		Launched map tasks=2
    		Launched reduce tasks=1
    		Data-local map tasks=2
    		Total time spent by all maps in occupied slots (ms)=5352
    		Total time spent by all reduces in occupied slots (ms)=2059
    		Total time spent by all map tasks (ms)=5352
    		Total time spent by all reduce tasks (ms)=2059
    		Total vcore-milliseconds taken by all map tasks=5352
    		Total vcore-milliseconds taken by all reduce tasks=2059
    		Total megabyte-milliseconds taken by all map tasks=5480448
    		Total megabyte-milliseconds taken by all reduce tasks=2108416
    	Map-Reduce Framework
    		Map input records=1000000
    		Map output records=1000000
    		Map output bytes=6000000
    		Map output materialized bytes=8000012
    		Input split bytes=196
    		Combine input records=0
    		Combine output records=0
    		Reduce input groups=7
    		Reduce shuffle bytes=8000012
    		Reduce input records=1000000
    		Reduce output records=7
    		Spilled Records=2000000
    		Shuffled Maps =2
    		Failed Shuffles=0
    		Merged Map outputs=2
    		GC time elapsed (ms)=142
    		CPU time spent (ms)=4920
    		Physical memory (bytes) snapshot=917086208
    		Virtual memory (bytes) snapshot=7854526464
    		Total committed heap usage (bytes)=981467136
    		Peak Map Physical memory (bytes)=283570176
    		Peak Map Virtual memory (bytes)=2614718464
    		Peak Reduce Physical memory (bytes)=351711232
    		Peak Reduce Virtual memory (bytes)=2629488640
    	Shuffle Errors
    		BAD_ID=0
    		CONNECTION=0
    		IO_ERROR=0
    		WRONG_LENGTH=0
    		WRONG_MAP=0
    		WRONG_REDUCE=0
    	File Input Format Counters 
    		Bytes Read=241985634
    	File Output Format Counters 
    		Bytes Written=77
    2025-12-16 15:42:40,917 INFO streaming.StreamJob: Output directory: /log



```python
!hdfs dfs -cat /log/part-00000
```

    200	142564
    303	142261
    304	143337
    403	143014
    404	142539
    500	142729
    502	143556


Tráfico Total por IP

En este segundo ejercicio el objetivo será identificar qué direcciones IP están consumiendo más ancho de banda.

Mapper:

Extrae la IP (el primer campo).

Extrae el tamaño de la respuesta en bytes (el número después del código de estado). Nota: a veces es un guion “-“ si es 0.
    
Emite (IP, bytes).
    
Reducer: Suma los bytes para cada IP.
    
Salida: 162.253.4.179: 5041 bytes


```python
%%writefile mapper_ejercicio_log1.py
#!/usr/bin/env python3
import sys

for line in sys.stdin:
    line = line.strip()

    if not line:
        continue

    parts = line.split(" ")

    if len(parts) < 10:
        continue

    ip = parts[0]

    bytes_sent = parts[9]

    if bytes_sent == "-":
        bytes_sent = 0
    else:
        try:
            bytes_sent = int(bytes_sent)
        except ValueError:
            continue

    print(f"{ip}\t{bytes_sent}")

```

    Writing mapper_ejercicio_log1.py



```python
%%writefile reducer_ejercicio_log1.py

#!/usr/bin/env python3
import sys

current_ip = None
current_total = 0

for line in sys.stdin:
    line = line.strip()

    if not line:
        continue

    parts = line.split('\t')
    if len(parts) != 2:
        continue

    ip, bytes_sent = parts

    try:
        bytes_sent = int(bytes_sent)
    except ValueError:
        continue

    if current_ip == ip:
        current_total += bytes_sent
    else:
        if current_ip is not None:
            print(f"{current_ip}\t{current_total}")

        current_ip = ip
        current_total = bytes_sent

if current_ip is not None:
    print(f"{current_ip}\t{current_total}")

```

    Writing reducer_ejercicio_log1.py



```python
!head logfiles.log | python3 mapper_ejercicio_log1.py | sort |python3 reducer_ejercicio_log1.py
```

    119.170.1.203	5011
    137.196.118.126	4960
    160.36.208.51	4979
    162.253.4.179	5041
    182.215.249.159	4936
    233.223.117.90	4963
    238.217.83.154	5152
    252.156.232.172	5028
    255.231.52.33	5054
    59.107.116.6	5008



```python
!hadoop jar /usr/local/hadoop/share/hadoop/tools/lib/hadoop-streaming-3.4.0.jar \
-files mapper_ejercicio_log1.py,reducer_ejercicio_log1.py \
-mapper "python3 mapper_ejercicio_log1.py" \
-reducer "python3 reducer_ejercicio_log1.py" \
-input /practica_log/logfiles.log \
-output /log1
```

    packageJobJar: [/tmp/hadoop-unjar4069141609690930574/] [] /tmp/streamjob8343070232104434674.jar tmpDir=null
    2025-12-16 15:47:45,106 INFO client.DefaultNoHARMFailoverProxyProvider: Connecting to ResourceManager at yarnmanager/172.19.0.6:8032
    2025-12-16 15:47:45,177 INFO client.DefaultNoHARMFailoverProxyProvider: Connecting to ResourceManager at yarnmanager/172.19.0.6:8032
    2025-12-16 15:47:45,305 INFO mapreduce.JobResourceUploader: Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/root/.staging/job_1765898224481_0008
    2025-12-16 15:47:45,526 INFO mapred.FileInputFormat: Total input files to process : 1
    2025-12-16 15:47:45,534 INFO net.NetworkTopology: Adding a new node: /default-rack/172.19.0.4:9866
    2025-12-16 15:47:45,535 INFO net.NetworkTopology: Adding a new node: /default-rack/172.19.0.2:9866
    2025-12-16 15:47:45,535 INFO net.NetworkTopology: Adding a new node: /default-rack/172.19.0.5:9866
    2025-12-16 15:47:45,572 INFO mapreduce.JobSubmitter: number of splits:2
    2025-12-16 15:47:45,639 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1765898224481_0008
    2025-12-16 15:47:45,640 INFO mapreduce.JobSubmitter: Executing with tokens: []
    2025-12-16 15:47:45,742 INFO conf.Configuration: resource-types.xml not found
    2025-12-16 15:47:45,742 INFO resource.ResourceUtils: Unable to find 'resource-types.xml'.
    2025-12-16 15:47:45,788 INFO impl.YarnClientImpl: Submitted application application_1765898224481_0008
    2025-12-16 15:47:45,812 INFO mapreduce.Job: The url to track the job: http://yarnmanager:8088/proxy/application_1765898224481_0008/
    2025-12-16 15:47:45,813 INFO mapreduce.Job: Running job: job_1765898224481_0008
    2025-12-16 15:47:49,859 INFO mapreduce.Job: Job job_1765898224481_0008 running in uber mode : false
    2025-12-16 15:47:49,860 INFO mapreduce.Job:  map 0% reduce 0%
    2025-12-16 15:47:55,030 INFO mapreduce.Job:  map 100% reduce 0%
    2025-12-16 15:48:00,056 INFO mapreduce.Job:  map 100% reduce 100%
    2025-12-16 15:48:00,073 INFO mapreduce.Job: Job job_1765898224481_0008 completed successfully
    2025-12-16 15:48:00,134 INFO mapreduce.Job: Counters: 55
    	File System Counters
    		FILE: Number of bytes read=21279925
    		FILE: Number of bytes written=43502596
    		FILE: Number of read operations=0
    		FILE: Number of large read operations=0
    		FILE: Number of write operations=0
    		HDFS: Number of bytes read=241985830
    		HDFS: Number of bytes written=19277383
    		HDFS: Number of read operations=11
    		HDFS: Number of large read operations=0
    		HDFS: Number of write operations=2
    		HDFS: Number of bytes read erasure-coded=0
    	Job Counters 
    		Launched map tasks=2
    		Launched reduce tasks=1
    		Data-local map tasks=1
    		Rack-local map tasks=1
    		Total time spent by all maps in occupied slots (ms)=5950
    		Total time spent by all reduces in occupied slots (ms)=2481
    		Total time spent by all map tasks (ms)=5950
    		Total time spent by all reduce tasks (ms)=2481
    		Total vcore-milliseconds taken by all map tasks=5950
    		Total vcore-milliseconds taken by all reduce tasks=2481
    		Total megabyte-milliseconds taken by all map tasks=6092800
    		Total megabyte-milliseconds taken by all reduce tasks=2540544
    	Map-Reduce Framework
    		Map input records=1000000
    		Map output records=1000000
    		Map output bytes=19279919
    		Map output materialized bytes=21279931
    		Input split bytes=196
    		Combine input records=0
    		Combine output records=0
    		Reduce input groups=999865
    		Reduce shuffle bytes=21279931
    		Reduce input records=1000000
    		Reduce output records=999865
    		Spilled Records=2000000
    		Shuffled Maps =2
    		Failed Shuffles=0
    		Merged Map outputs=2
    		GC time elapsed (ms)=172
    		CPU time spent (ms)=6480
    		Physical memory (bytes) snapshot=949587968
    		Virtual memory (bytes) snapshot=7853191168
    		Total committed heap usage (bytes)=1001914368
    		Peak Map Physical memory (bytes)=284897280
    		Peak Map Virtual memory (bytes)=2615091200
    		Peak Reduce Physical memory (bytes)=383311872
    		Peak Reduce Virtual memory (bytes)=2626052096
    	Shuffle Errors
    		BAD_ID=0
    		CONNECTION=0
    		IO_ERROR=0
    		WRONG_LENGTH=0
    		WRONG_MAP=0
    		WRONG_REDUCE=0
    	File Input Format Counters 
    		Bytes Read=241985634
    	File Output Format Counters 
    		Bytes Written=19277383
    2025-12-16 15:48:00,134 INFO streaming.StreamJob: Output directory: /log1



```python
!hdfs dfs -head /log1/part-00000
```

    0.0.106.234	4998
    0.0.116.227	4927
    0.0.142.71	4936
    0.0.144.143	5030
    0.0.201.132	4945
    0.0.213.195	4917
    0.0.253.11	5036
    0.0.36.22	4996
    0.0.47.93	4910
    0.0.7.115	4951
    0.0.71.76	5028
    0.0.87.207	4975
    0.0.94.174	5093
    0.1.1.75	5008
    0.1.122.253	4983
    0.1.193.166	4996
    0.1.221.62	4972
    0.1.230.154	5028
    0.1.236.188	4971
    0.1.242.149	4962
    0.1.254.162	4921
    0.1.5.80	4951
    0.10.128.105	5040
    0.10.137.129	4984
    0.10.137.223	4981
    0.10.154.78	4906
    0.10.166.243	5022
    0.10.181.9	5046
    0.10.183.4	4913
    0.10.189.37	5021
    0.10.197.164	4981
    0.10.203.205	5045
    0.10.243.165	4976
    0.10.37.229	4911
    0.10.66.162	5038
    0.10.85.36	5020
    0.10.86.4	5041
    0.100.110.37	4955
    0.100.143.180	4982
    0.100.156.70	4926
    0.100.166.29	4966
    0.100.18.185	4945
    0.100.19.188	5065
    0.100.248.212	5025
    0.100.40.202	5053
    0.100.49.184	5035
    0.100.58.65	5089
    0.100.67.120	5101
    0.100.71.221	5055
    0.100.80.218	5053
    0.101.112.73	4961
    0.101.135.35	4977
    0.101.149.120	4997
    0.101.164.255	5071
    0.101.169.189	4981
    0.101.17.19	5086
    0.101.186.239	5025
    0.101.200.49	5036
    0.101.23.105	4964
    0.101.237.0	

### 2. Análisis de comportamiento

URLs más populares

El objetivo en este ejercicio será encontrar las las rutas (/usr/admin, /usr/register) más solicitadas.

Mapper:

Analiza la cadena de petición DELETE /usr/admin HTTP/1.0.

Extrae la URL (el segundo elemento entre las comillas).

Emite (url, 1).

Reducer: Suma las visitas.

Salida: Muestra todas las URLs y el número de accesos a cada una

Opcional: ¿Cómo mostrarías sólo las top 10? (Requiere un segundo paso de ordenación o un reducer inteligente).



```python
%%writefile mapper_ejercicio_log2.py
#!/usr/bin/env python3
import sys

for line in sys.stdin:
    line = line.strip()

    if not line:
        continue

    # La petición está entre comillas
    try:
        request = line.split('"')[1]
    except IndexError:
        continue

    parts = request.split(" ")
    if len(parts) < 2:
        continue

    url = parts[1]

    print(f"{url}\t1")

```

    Writing mapper_ejercicio_log2.py



```python
%%writefile reducer_ejercicio_log2.py
#!/usr/bin/env python3
import sys

current_url = None
current_count = 0

for line in sys.stdin:
    line = line.strip()

    if not line:
        continue

    parts = line.split('\t')
    if len(parts) != 2:
        continue

    url, count = parts

    try:
        count = int(count)
    except ValueError:
        continue

    if current_url == url:
        current_count += count
    else:
        if current_url is not None:
            print(f"{current_url}\t{current_count}")

        current_url = url
        current_count = count

if current_url is not None:
    print(f"{current_url}\t{current_count}")

```

    Writing reducer_ejercicio_log2.py



```python
!head logfiles.log | python3 mapper_ejercicio_log2.py | sort |python3 reducer_ejercicio_log2.py
```

    /usr	3
    /usr/admin	2
    /usr/admin/developer	2
    /usr/register	3



```python
!hadoop jar /usr/local/hadoop/share/hadoop/tools/lib/hadoop-streaming-3.4.0.jar \
-files mapper_ejercicio_log2.py,reducer_ejercicio_log2.py \
-mapper "python3 mapper_ejercicio_log2.py" \
-reducer "python3 reducer_ejercicio_log2.py" \
-input /practica_log/logfiles.log \
-output /log2
```

    packageJobJar: [/tmp/hadoop-unjar1713569418787703233/] [] /tmp/streamjob1214609763582506913.jar tmpDir=null
    2025-12-16 15:52:02,057 INFO client.DefaultNoHARMFailoverProxyProvider: Connecting to ResourceManager at yarnmanager/172.19.0.6:8032
    2025-12-16 15:52:02,129 INFO client.DefaultNoHARMFailoverProxyProvider: Connecting to ResourceManager at yarnmanager/172.19.0.6:8032
    2025-12-16 15:52:02,274 INFO mapreduce.JobResourceUploader: Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/root/.staging/job_1765898224481_0009
    2025-12-16 15:52:02,495 INFO mapred.FileInputFormat: Total input files to process : 1
    2025-12-16 15:52:02,504 INFO net.NetworkTopology: Adding a new node: /default-rack/172.19.0.2:9866
    2025-12-16 15:52:02,504 INFO net.NetworkTopology: Adding a new node: /default-rack/172.19.0.4:9866
    2025-12-16 15:52:02,504 INFO net.NetworkTopology: Adding a new node: /default-rack/172.19.0.5:9866
    2025-12-16 15:52:02,543 INFO mapreduce.JobSubmitter: number of splits:2
    2025-12-16 15:52:02,607 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1765898224481_0009
    2025-12-16 15:52:02,607 INFO mapreduce.JobSubmitter: Executing with tokens: []
    2025-12-16 15:52:02,714 INFO conf.Configuration: resource-types.xml not found
    2025-12-16 15:52:02,714 INFO resource.ResourceUtils: Unable to find 'resource-types.xml'.
    2025-12-16 15:52:02,758 INFO impl.YarnClientImpl: Submitted application application_1765898224481_0009
    2025-12-16 15:52:02,783 INFO mapreduce.Job: The url to track the job: http://yarnmanager:8088/proxy/application_1765898224481_0009/
    2025-12-16 15:52:02,784 INFO mapreduce.Job: Running job: job_1765898224481_0009
    2025-12-16 15:52:06,840 INFO mapreduce.Job: Job job_1765898224481_0009 running in uber mode : false
    2025-12-16 15:52:06,841 INFO mapreduce.Job:  map 0% reduce 0%
    2025-12-16 15:52:11,882 INFO mapreduce.Job:  map 100% reduce 0%
    2025-12-16 15:52:15,901 INFO mapreduce.Job:  map 100% reduce 100%
    2025-12-16 15:52:16,929 INFO mapreduce.Job: Job job_1765898224481_0009 completed successfully
    2025-12-16 15:52:16,989 INFO mapreduce.Job: Counters: 54
    	File System Counters
    		FILE: Number of bytes read=16398596
    		FILE: Number of bytes written=33739938
    		FILE: Number of read operations=0
    		FILE: Number of large read operations=0
    		FILE: Number of write operations=0
    		HDFS: Number of bytes read=241985830
    		HDFS: Number of bytes written=97
    		HDFS: Number of read operations=11
    		HDFS: Number of large read operations=0
    		HDFS: Number of write operations=2
    		HDFS: Number of bytes read erasure-coded=0
    	Job Counters 
    		Launched map tasks=2
    		Launched reduce tasks=1
    		Data-local map tasks=2
    		Total time spent by all maps in occupied slots (ms)=5297
    		Total time spent by all reduces in occupied slots (ms)=2191
    		Total time spent by all map tasks (ms)=5297
    		Total time spent by all reduce tasks (ms)=2191
    		Total vcore-milliseconds taken by all map tasks=5297
    		Total vcore-milliseconds taken by all reduce tasks=2191
    		Total megabyte-milliseconds taken by all map tasks=5424128
    		Total megabyte-milliseconds taken by all reduce tasks=2243584
    	Map-Reduce Framework
    		Map input records=1000000
    		Map output records=1000000
    		Map output bytes=14398590
    		Map output materialized bytes=16398602
    		Input split bytes=196
    		Combine input records=0
    		Combine output records=0
    		Reduce input groups=5
    		Reduce shuffle bytes=16398602
    		Reduce input records=1000000
    		Reduce output records=5
    		Spilled Records=2000000
    		Shuffled Maps =2
    		Failed Shuffles=0
    		Merged Map outputs=2
    		GC time elapsed (ms)=177
    		CPU time spent (ms)=4820
    		Physical memory (bytes) snapshot=948613120
    		Virtual memory (bytes) snapshot=7848341504
    		Total committed heap usage (bytes)=967835648
    		Peak Map Physical memory (bytes)=341192704
    		Peak Map Virtual memory (bytes)=2612535296
    		Peak Reduce Physical memory (bytes)=320860160
    		Peak Reduce Virtual memory (bytes)=2624069632
    	Shuffle Errors
    		BAD_ID=0
    		CONNECTION=0
    		IO_ERROR=0
    		WRONG_LENGTH=0
    		WRONG_MAP=0
    		WRONG_REDUCE=0
    	File Input Format Counters 
    		Bytes Read=241985634
    	File Output Format Counters 
    		Bytes Written=97
    2025-12-16 15:52:16,989 INFO streaming.StreamJob: Output directory: /log2



```python
!hdfs dfs -cat /log2/part-00000
```

    /usr	200383
    /usr/admin	199096
    /usr/admin/developer	200000
    /usr/login	200225
    /usr/register	200296



## Distribución por Método HTTP

Aquí queremos saber qué tipo de acciones hacen los usuarios (GET vs POST vs DELETE).

Mapper: Extrae el verbo HTTP (GET, POST, PUT, DELETE). Emite (método, 1).

Reducer: Suma contadores.


```python
%%writefile mapper_ejercicio_log3.py
#!/usr/bin/env python3
import sys

for line in sys.stdin:
    line = line.strip()

    if not line:
        continue


    try:
        request = line.split('"')[1]
    except IndexError:
        continue

    parts = request.split(" ")
    if len(parts) < 1:
        continue

    method = parts[0]

    print(f"{method}\t1")


```

    Writing mapper_ejercicio_log3.py



```python
%%writefile reducer_ejercicio_log3.py
#!/usr/bin/env python3
import sys

current_method = None
current_count = 0

for line in sys.stdin:
    line = line.strip()

    if not line:
        continue

    parts = line.split('\t')
    if len(parts) != 2:
        continue

    method, count = parts

    try:
        count = int(count)
    except ValueError:
        continue

    if current_method == method:
        current_count += count
    else:
        if current_method is not None:
            print(f"{current_method}\t{current_count}")

        current_method = method
        current_count = count

# Emitir el último método
if current_method is not None:
    print(f"{current_method}\t{current_count}")

```

    Writing reducer_ejercicio_log3.py



```python
!head logfiles.log | python3 mapper_ejercicio_log3.py | sort |python3 reducer_ejercicio_log3.py
```

    DELETE	3
    GET	2
    POST	3
    PUT	2



```python
!hadoop jar /usr/local/hadoop/share/hadoop/tools/lib/hadoop-streaming-3.4.0.jar \
-files mapper_ejercicio_log3.py,reducer_ejercicio_log3.py \
-mapper "python3 mapper_ejercicio_log3.py" \
-reducer "python3 reducer_ejercicio_log3.py" \
-input /practica_log/logfiles.log \
-output /log3
```

    packageJobJar: [/tmp/hadoop-unjar6153037945842916264/] [] /tmp/streamjob3804613954686337461.jar tmpDir=null
    2025-12-16 15:57:14,071 INFO client.DefaultNoHARMFailoverProxyProvider: Connecting to ResourceManager at yarnmanager/172.19.0.6:8032
    2025-12-16 15:57:14,152 INFO client.DefaultNoHARMFailoverProxyProvider: Connecting to ResourceManager at yarnmanager/172.19.0.6:8032
    2025-12-16 15:57:14,301 INFO mapreduce.JobResourceUploader: Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/root/.staging/job_1765898224481_0010
    2025-12-16 15:57:14,611 INFO mapred.FileInputFormat: Total input files to process : 1
    2025-12-16 15:57:14,621 INFO net.NetworkTopology: Adding a new node: /default-rack/172.19.0.2:9866
    2025-12-16 15:57:14,621 INFO net.NetworkTopology: Adding a new node: /default-rack/172.19.0.4:9866
    2025-12-16 15:57:14,621 INFO net.NetworkTopology: Adding a new node: /default-rack/172.19.0.5:9866
    2025-12-16 15:57:14,674 INFO mapreduce.JobSubmitter: number of splits:2
    2025-12-16 15:57:14,755 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1765898224481_0010
    2025-12-16 15:57:14,755 INFO mapreduce.JobSubmitter: Executing with tokens: []
    2025-12-16 15:57:14,891 INFO conf.Configuration: resource-types.xml not found
    2025-12-16 15:57:14,891 INFO resource.ResourceUtils: Unable to find 'resource-types.xml'.
    2025-12-16 15:57:14,947 INFO impl.YarnClientImpl: Submitted application application_1765898224481_0010
    2025-12-16 15:57:14,978 INFO mapreduce.Job: The url to track the job: http://yarnmanager:8088/proxy/application_1765898224481_0010/
    2025-12-16 15:57:14,979 INFO mapreduce.Job: Running job: job_1765898224481_0010
    2025-12-16 15:57:19,035 INFO mapreduce.Job: Job job_1765898224481_0010 running in uber mode : false
    2025-12-16 15:57:19,036 INFO mapreduce.Job:  map 0% reduce 0%
    2025-12-16 15:57:24,078 INFO mapreduce.Job:  map 100% reduce 0%
    2025-12-16 15:57:28,208 INFO mapreduce.Job:  map 100% reduce 100%
    2025-12-16 15:57:28,223 INFO mapreduce.Job: Job job_1765898224481_0010 completed successfully
    2025-12-16 15:57:28,279 INFO mapreduce.Job: Counters: 55
    	File System Counters
    		FILE: Number of bytes read=8998241
    		FILE: Number of bytes written=18939228
    		FILE: Number of read operations=0
    		FILE: Number of large read operations=0
    		FILE: Number of write operations=0
    		HDFS: Number of bytes read=241985830
    		HDFS: Number of bytes written=48
    		HDFS: Number of read operations=11
    		HDFS: Number of large read operations=0
    		HDFS: Number of write operations=2
    		HDFS: Number of bytes read erasure-coded=0
    	Job Counters 
    		Launched map tasks=2
    		Launched reduce tasks=1
    		Data-local map tasks=1
    		Rack-local map tasks=1
    		Total time spent by all maps in occupied slots (ms)=5152
    		Total time spent by all reduces in occupied slots (ms)=2129
    		Total time spent by all map tasks (ms)=5152
    		Total time spent by all reduce tasks (ms)=2129
    		Total vcore-milliseconds taken by all map tasks=5152
    		Total vcore-milliseconds taken by all reduce tasks=2129
    		Total megabyte-milliseconds taken by all map tasks=5275648
    		Total megabyte-milliseconds taken by all reduce tasks=2180096
    	Map-Reduce Framework
    		Map input records=1000000
    		Map output records=1000000
    		Map output bytes=6998235
    		Map output materialized bytes=8998247
    		Input split bytes=196
    		Combine input records=0
    		Combine output records=0
    		Reduce input groups=4
    		Reduce shuffle bytes=8998247
    		Reduce input records=1000000
    		Reduce output records=4
    		Spilled Records=2000000
    		Shuffled Maps =2
    		Failed Shuffles=0
    		Merged Map outputs=2
    		GC time elapsed (ms)=124
    		CPU time spent (ms)=4740
    		Physical memory (bytes) snapshot=897146880
    		Virtual memory (bytes) snapshot=7850393600
    		Total committed heap usage (bytes)=961544192
    		Peak Map Physical memory (bytes)=284569600
    		Peak Map Virtual memory (bytes)=2614071296
    		Peak Reduce Physical memory (bytes)=330170368
    		Peak Reduce Virtual memory (bytes)=2624299008
    	Shuffle Errors
    		BAD_ID=0
    		CONNECTION=0
    		IO_ERROR=0
    		WRONG_LENGTH=0
    		WRONG_MAP=0
    		WRONG_REDUCE=0
    	File Input Format Counters 
    		Bytes Read=241985634
    	File Output Format Counters 
    		Bytes Written=48
    2025-12-16 15:57:28,279 INFO streaming.StreamJob: Output directory: /log3



```python
!hdfs dfs -cat /log3/part-00000
```

    DELETE	249768
    GET	250515
    POST	248931
    PUT	250786


## Análisis de navegadores

El objetivo aquí es saber si los usuarios usan Chrome, Firefox, o si son bots/móviles.

Mapper:

Extrae la cadena larga del final (User-Agent).

Busca palabras clave simples: si contiene “Chrome” emite ("Chrome", 1), si “Firefox” emite ("Firefox", 1), etc.

Reducer: Suma totales por navegador.



```python
%%writefile mapper_ejercicio_log4.py
#!/usr/bin/env python3
import sys

for line in sys.stdin:
    line = line.strip()

    if not line:
        continue

    try:
        user_agent = line.split('"')[-2]
    except IndexError:
        continue

    browser = "Other"

    if "Chrome" in user_agent and "Edg" not in user_agent and "OPR" not in user_agent:
        browser = "Chrome"
    elif "Firefox" in user_agent:
        browser = "Firefox"
    elif "Edg" in user_agent:
        browser = "Edge"
    elif "OPR" in user_agent:
        browser = "Opera"
    elif "Mobile" in user_agent or "Android" in user_agent:
        browser = "Mobile"
    elif "bot" in user_agent.lower():
        browser = "Bot"

    print(f"{browser}\t1")


```

    Writing mapper_ejercicio_log4.py



```python
%%writefile reducer_ejercicio_log4.py
#!/usr/bin/env python3
import sys

current_browser = None
current_count = 0

for line in sys.stdin:
    line = line.strip()

    if not line:
        continue

    parts = line.split('\t')
    if len(parts) != 2:
        continue

    browser, count = parts

    try:
        count = int(count)
    except ValueError:
        continue

    if current_browser == browser:
        current_count += count
    else:
        if current_browser is not None:
            print(f"{current_browser}\t{current_count}")

        current_browser = browser
        current_count = count


if current_browser is not None:
    print(f"{current_browser}\t{current_count}")

```

    Writing reducer_ejercicio_log4.py



```python
!head logfiles.log | python3 mapper_ejercicio_log4.py | sort |python3 reducer_ejercicio_log4.py
```

    Chrome	2
    Edge	2
    Firefox	1
    Mobile	1
    Opera	3
    Other	1



```python
!hadoop jar /usr/local/hadoop/share/hadoop/tools/lib/hadoop-streaming-3.4.0.jar \
-files mapper_ejercicio_log4.py,reducer_ejercicio_log4.py \
-mapper "python3 mapper_ejercicio_log4.py" \
-reducer "python3 reducer_ejercicio_log4.py" \
-input /practica_log/logfiles.log \
-output /log4
```

    packageJobJar: [/tmp/hadoop-unjar8654004528412744148/] [] /tmp/streamjob2981363266135050731.jar tmpDir=null
    2025-12-16 15:59:51,775 INFO client.DefaultNoHARMFailoverProxyProvider: Connecting to ResourceManager at yarnmanager/172.19.0.6:8032
    2025-12-16 15:59:51,879 INFO client.DefaultNoHARMFailoverProxyProvider: Connecting to ResourceManager at yarnmanager/172.19.0.6:8032
    2025-12-16 15:59:52,031 INFO mapreduce.JobResourceUploader: Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/root/.staging/job_1765898224481_0011
    2025-12-16 15:59:52,358 INFO mapred.FileInputFormat: Total input files to process : 1
    2025-12-16 15:59:52,369 INFO net.NetworkTopology: Adding a new node: /default-rack/172.19.0.5:9866
    2025-12-16 15:59:52,369 INFO net.NetworkTopology: Adding a new node: /default-rack/172.19.0.4:9866
    2025-12-16 15:59:52,369 INFO net.NetworkTopology: Adding a new node: /default-rack/172.19.0.2:9866
    2025-12-16 15:59:52,406 INFO mapreduce.JobSubmitter: number of splits:2
    2025-12-16 15:59:52,472 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1765898224481_0011
    2025-12-16 15:59:52,473 INFO mapreduce.JobSubmitter: Executing with tokens: []
    2025-12-16 15:59:52,576 INFO conf.Configuration: resource-types.xml not found
    2025-12-16 15:59:52,577 INFO resource.ResourceUtils: Unable to find 'resource-types.xml'.
    2025-12-16 15:59:52,616 INFO impl.YarnClientImpl: Submitted application application_1765898224481_0011
    2025-12-16 15:59:52,637 INFO mapreduce.Job: The url to track the job: http://yarnmanager:8088/proxy/application_1765898224481_0011/
    2025-12-16 15:59:52,638 INFO mapreduce.Job: Running job: job_1765898224481_0011
    2025-12-16 15:59:56,800 INFO mapreduce.Job: Job job_1765898224481_0011 running in uber mode : false
    2025-12-16 15:59:56,802 INFO mapreduce.Job:  map 0% reduce 0%
    2025-12-16 16:00:01,858 INFO mapreduce.Job:  map 100% reduce 0%
    2025-12-16 16:00:05,874 INFO mapreduce.Job:  map 100% reduce 100%
    2025-12-16 16:00:05,885 INFO mapreduce.Job: Job job_1765898224481_0011 completed successfully
    2025-12-16 16:00:05,936 INFO mapreduce.Job: Counters: 55
    	File System Counters
    		FILE: Number of bytes read=10500475
    		FILE: Number of bytes written=21943696
    		FILE: Number of read operations=0
    		FILE: Number of large read operations=0
    		FILE: Number of write operations=0
    		HDFS: Number of bytes read=241985830
    		HDFS: Number of bytes written=81
    		HDFS: Number of read operations=11
    		HDFS: Number of large read operations=0
    		HDFS: Number of write operations=2
    		HDFS: Number of bytes read erasure-coded=0
    	Job Counters 
    		Launched map tasks=2
    		Launched reduce tasks=1
    		Data-local map tasks=1
    		Rack-local map tasks=1
    		Total time spent by all maps in occupied slots (ms)=5393
    		Total time spent by all reduces in occupied slots (ms)=2091
    		Total time spent by all map tasks (ms)=5393
    		Total time spent by all reduce tasks (ms)=2091
    		Total vcore-milliseconds taken by all map tasks=5393
    		Total vcore-milliseconds taken by all reduce tasks=2091
    		Total megabyte-milliseconds taken by all map tasks=5522432
    		Total megabyte-milliseconds taken by all reduce tasks=2141184
    	Map-Reduce Framework
    		Map input records=1000000
    		Map output records=1000000
    		Map output bytes=8500469
    		Map output materialized bytes=10500481
    		Input split bytes=196
    		Combine input records=0
    		Combine output records=0
    		Reduce input groups=6
    		Reduce shuffle bytes=10500481
    		Reduce input records=1000000
    		Reduce output records=6
    		Spilled Records=2000000
    		Shuffled Maps =2
    		Failed Shuffles=0
    		Merged Map outputs=2
    		GC time elapsed (ms)=158
    		CPU time spent (ms)=4550
    		Physical memory (bytes) snapshot=938176512
    		Virtual memory (bytes) snapshot=7852859392
    		Total committed heap usage (bytes)=974127104
    		Peak Map Physical memory (bytes)=283283456
    		Peak Map Virtual memory (bytes)=2613243904
    		Peak Reduce Physical memory (bytes)=375582720
    		Peak Reduce Virtual memory (bytes)=2626711552
    	Shuffle Errors
    		BAD_ID=0
    		CONNECTION=0
    		IO_ERROR=0
    		WRONG_LENGTH=0
    		WRONG_MAP=0
    		WRONG_REDUCE=0
    	File Input Format Counters 
    		Bytes Read=241985634
    	File Output Format Counters 
    		Bytes Written=81
    2025-12-16 16:00:05,936 INFO streaming.StreamJob: Output directory: /log4



```python
!hdfs dfs -cat /log4/part-00000
```

    Chrome	199620
    Edge	199460
    Firefox	199953
    Mobile	100403
    Opera	200429
    Other	100135


## 3. Análisis temporal y de sesión

   
Picos de tráfico por hora

Queremos descubrir a qué hora del día el servidor recibe más carga.

Mapper:

Parsea el campo de fecha [27/Dec/2037:12:00:00 +0530].

Extrae la hora (12).

Emite (hora, 1).

Reducer: Suma las peticiones por hora.




```python
%%writefile mapper_ejercicio_log5.py
#!/usr/bin/env python3
import sys

for line in sys.stdin:
    line = line.strip()

    if not line:
        continue

    
    try:
        datetime_field = line.split('[')[1].split(']')[0]
    except IndexError:
        continue

 
    try:
        date_time = datetime_field.split(' ')[0]
        hour = date_time.split(':')[1]
    except IndexError:
        continue

    print(f"{hour}\t1")

```

    Writing mapper_ejercicio_log5.py



```python
%%writefile reducer_ejercicio_log5.py
#!/usr/bin/env python3
import sys

current_hour = None
current_count = 0

for line in sys.stdin:
    line = line.strip()

    if not line:
        continue

    parts = line.split('\t')
    if len(parts) != 2:
        continue

    hour, count = parts

    try:
        count = int(count)
    except ValueError:
        continue

    if current_hour == hour:
        current_count += count
    else:
        if current_hour is not None:
            print(f"{current_hour}\t{current_count}")

        current_hour = hour
        current_count = count


if current_hour is not None:
    print(f"{current_hour}\t{current_count}")

```

    Writing reducer_ejercicio_log5.py



```python
!head logfiles.log | python3 mapper_ejercicio_log5.py | sort |python3 reducer_ejercicio_log5.py
```

    12	10



```python
!hadoop jar /usr/local/hadoop/share/hadoop/tools/lib/hadoop-streaming-3.4.0.jar \
-files mapper_ejercicio_log5.py,reducer_ejercicio_log5.py \
-mapper "python3 mapper_ejercicio_log5.py" \
-reducer "python3 reducer_ejercicio_log5.py" \
-input /practica_log/logfiles.log \
-output /log5
```

    packageJobJar: [/tmp/hadoop-unjar5217665615508274543/] [] /tmp/streamjob2420780773370149025.jar tmpDir=null
    2025-12-16 16:07:01,044 INFO client.DefaultNoHARMFailoverProxyProvider: Connecting to ResourceManager at yarnmanager/172.19.0.6:8032
    2025-12-16 16:07:01,119 INFO client.DefaultNoHARMFailoverProxyProvider: Connecting to ResourceManager at yarnmanager/172.19.0.6:8032
    2025-12-16 16:07:01,263 INFO mapreduce.JobResourceUploader: Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/root/.staging/job_1765898224481_0014
    2025-12-16 16:07:01,491 INFO mapred.FileInputFormat: Total input files to process : 1
    2025-12-16 16:07:01,499 INFO net.NetworkTopology: Adding a new node: /default-rack/172.19.0.4:9866
    2025-12-16 16:07:01,500 INFO net.NetworkTopology: Adding a new node: /default-rack/172.19.0.2:9866
    2025-12-16 16:07:01,500 INFO net.NetworkTopology: Adding a new node: /default-rack/172.19.0.5:9866
    2025-12-16 16:07:01,540 INFO mapreduce.JobSubmitter: number of splits:2
    2025-12-16 16:07:01,607 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1765898224481_0014
    2025-12-16 16:07:01,607 INFO mapreduce.JobSubmitter: Executing with tokens: []
    2025-12-16 16:07:01,717 INFO conf.Configuration: resource-types.xml not found
    2025-12-16 16:07:01,717 INFO resource.ResourceUtils: Unable to find 'resource-types.xml'.
    2025-12-16 16:07:01,770 INFO impl.YarnClientImpl: Submitted application application_1765898224481_0014
    2025-12-16 16:07:01,804 INFO mapreduce.Job: The url to track the job: http://yarnmanager:8088/proxy/application_1765898224481_0014/
    2025-12-16 16:07:01,806 INFO mapreduce.Job: Running job: job_1765898224481_0014
    2025-12-16 16:07:05,854 INFO mapreduce.Job: Job job_1765898224481_0014 running in uber mode : false
    2025-12-16 16:07:05,857 INFO mapreduce.Job:  map 0% reduce 0%
    2025-12-16 16:07:09,905 INFO mapreduce.Job:  map 100% reduce 0%
    2025-12-16 16:07:14,931 INFO mapreduce.Job:  map 100% reduce 100%
    2025-12-16 16:07:14,949 INFO mapreduce.Job: Job job_1765898224481_0014 completed successfully
    2025-12-16 16:07:15,016 INFO mapreduce.Job: Counters: 54
    	File System Counters
    		FILE: Number of bytes read=7000006
    		FILE: Number of bytes written=14942758
    		FILE: Number of read operations=0
    		FILE: Number of large read operations=0
    		FILE: Number of write operations=0
    		HDFS: Number of bytes read=241985830
    		HDFS: Number of bytes written=11
    		HDFS: Number of read operations=11
    		HDFS: Number of large read operations=0
    		HDFS: Number of write operations=2
    		HDFS: Number of bytes read erasure-coded=0
    	Job Counters 
    		Launched map tasks=2
    		Launched reduce tasks=1
    		Data-local map tasks=2
    		Total time spent by all maps in occupied slots (ms)=4984
    		Total time spent by all reduces in occupied slots (ms)=2089
    		Total time spent by all map tasks (ms)=4984
    		Total time spent by all reduce tasks (ms)=2089
    		Total vcore-milliseconds taken by all map tasks=4984
    		Total vcore-milliseconds taken by all reduce tasks=2089
    		Total megabyte-milliseconds taken by all map tasks=5103616
    		Total megabyte-milliseconds taken by all reduce tasks=2139136
    	Map-Reduce Framework
    		Map input records=1000000
    		Map output records=1000000
    		Map output bytes=5000000
    		Map output materialized bytes=7000012
    		Input split bytes=196
    		Combine input records=0
    		Combine output records=0
    		Reduce input groups=1
    		Reduce shuffle bytes=7000012
    		Reduce input records=1000000
    		Reduce output records=1
    		Spilled Records=2000000
    		Shuffled Maps =2
    		Failed Shuffles=0
    		Merged Map outputs=2
    		GC time elapsed (ms)=140
    		CPU time spent (ms)=3850
    		Physical memory (bytes) snapshot=877707264
    		Virtual memory (bytes) snapshot=7846666240
    		Total committed heap usage (bytes)=968359936
    		Peak Map Physical memory (bytes)=280506368
    		Peak Map Virtual memory (bytes)=2612838400
    		Peak Reduce Physical memory (bytes)=316821504
    		Peak Reduce Virtual memory (bytes)=2621820928
    	Shuffle Errors
    		BAD_ID=0
    		CONNECTION=0
    		IO_ERROR=0
    		WRONG_LENGTH=0
    		WRONG_MAP=0
    		WRONG_REDUCE=0
    	File Input Format Counters 
    		Bytes Read=241985634
    	File Output Format Counters 
    		Bytes Written=11
    2025-12-16 16:07:15,017 INFO streaming.StreamJob: Output directory: /log5



```python
!hdfs dfs -cat /log5/part-00000
```

    12	1000000


## Tasa de error por endpoint

En este ejercicio queremos descubrir qué URLs están fallando más.


Mapper:

Extrae la URL y el código de estado.

Si el código es >= 400, emite (url, "error").

Si el código es < 400, emite (url, "ok").

O mejor: emite (url, (1, 0)) para éxito y (url, (0, 1)) para error.

Reducer: Suma totales y errores. Calcula el % de error: (errores / total) * 100.


```python
%%writefile mapper_ejercicio_log6.py

#!/usr/bin/env python3
import sys

for line in sys.stdin:
    line = line.strip()

    if not line:
        continue

 
    try:
        request = line.split('"')[1]
    except IndexError:
        continue

    req_parts = request.split(" ")
    if len(req_parts) < 2:
        continue

    url = req_parts[1]


    parts = line.split(" ")
    if len(parts) < 9:
        continue

    try:
        status_code = int(parts[8])
    except ValueError:
        continue


    if status_code >= 400:
        print(f"{url}\t0\t1")
    else:
        print(f"{url}\t1\t0")

```

    Writing mapper_ejercicio_log6.py



```python
%%writefile reducer_ejercicio_log6.py
#!/usr/bin/env python3
import sys

current_url = None
ok_count = 0
error_count = 0

for line in sys.stdin:
    line = line.strip()

    if not line:
        continue

    parts = line.split('\t')
    if len(parts) != 3:
        continue

    url, ok, error = parts

    try:
        ok = int(ok)
        error = int(error)
    except ValueError:
        continue

    if current_url == url:
        ok_count += ok
        error_count += error
    else:
        if current_url is not None:
            total = ok_count + error_count
            error_rate = (error_count / total) * 100 if total > 0 else 0
            print(f"{current_url}\t{ok_count}\t{error_count}\t{error_rate:.2f}%")

        current_url = url
        ok_count = ok
        error_count = error


if current_url is not None:
    total = ok_count + error_count
    error_rate = (error_count / total) * 100 if total > 0 else 0
    print(f"{current_url}\t{ok_count}\t{error_count}\t{error_rate:.2f}%")

```

    Writing reducer_ejercicio_log6.py



```python
!head logfiles.log | python3 mapper_ejercicio_log6.py | sort |python3 reducer_ejercicio_log6.py
```

    /usr	2	1	33.33%
    /usr/admin	0	2	100.00%
    /usr/admin/developer	1	1	50.00%
    /usr/register	2	1	33.33%



```python
!hadoop jar /usr/local/hadoop/share/hadoop/tools/lib/hadoop-streaming-3.4.0.jar \
-files mapper_ejercicio_log6.py,reducer_ejercicio_log6.py \
-mapper "python3 mapper_ejercicio_log6.py" \
-reducer "python3 reducer_ejercicio_log6.py" \
-input /practica_log/logfiles.log \
-output /log6
```

    packageJobJar: [/tmp/hadoop-unjar6685026003194457138/] [] /tmp/streamjob7854388933219620939.jar tmpDir=null
    2025-12-16 16:09:22,976 INFO client.DefaultNoHARMFailoverProxyProvider: Connecting to ResourceManager at yarnmanager/172.19.0.6:8032
    2025-12-16 16:09:23,049 INFO client.DefaultNoHARMFailoverProxyProvider: Connecting to ResourceManager at yarnmanager/172.19.0.6:8032
    2025-12-16 16:09:23,198 INFO mapreduce.JobResourceUploader: Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/root/.staging/job_1765898224481_0015
    2025-12-16 16:09:23,443 INFO mapred.FileInputFormat: Total input files to process : 1
    2025-12-16 16:09:23,452 INFO net.NetworkTopology: Adding a new node: /default-rack/172.19.0.2:9866
    2025-12-16 16:09:23,453 INFO net.NetworkTopology: Adding a new node: /default-rack/172.19.0.4:9866
    2025-12-16 16:09:23,453 INFO net.NetworkTopology: Adding a new node: /default-rack/172.19.0.5:9866
    2025-12-16 16:09:23,502 INFO mapreduce.JobSubmitter: number of splits:2
    2025-12-16 16:09:23,589 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1765898224481_0015
    2025-12-16 16:09:23,590 INFO mapreduce.JobSubmitter: Executing with tokens: []
    2025-12-16 16:09:23,708 INFO conf.Configuration: resource-types.xml not found
    2025-12-16 16:09:23,708 INFO resource.ResourceUtils: Unable to find 'resource-types.xml'.
    2025-12-16 16:09:23,754 INFO impl.YarnClientImpl: Submitted application application_1765898224481_0015
    2025-12-16 16:09:23,792 INFO mapreduce.Job: The url to track the job: http://yarnmanager:8088/proxy/application_1765898224481_0015/
    2025-12-16 16:09:23,794 INFO mapreduce.Job: Running job: job_1765898224481_0015
    2025-12-16 16:09:27,838 INFO mapreduce.Job: Job job_1765898224481_0015 running in uber mode : false
    2025-12-16 16:09:27,839 INFO mapreduce.Job:  map 0% reduce 0%
    2025-12-16 16:09:33,009 INFO mapreduce.Job:  map 100% reduce 0%
    2025-12-16 16:09:38,033 INFO mapreduce.Job:  map 100% reduce 100%
    2025-12-16 16:09:38,048 INFO mapreduce.Job: Job job_1765898224481_0015 completed successfully
    2025-12-16 16:09:38,109 INFO mapreduce.Job: Counters: 55
    	File System Counters
    		FILE: Number of bytes read=18398596
    		FILE: Number of bytes written=37739938
    		FILE: Number of read operations=0
    		FILE: Number of large read operations=0
    		FILE: Number of write operations=0
    		HDFS: Number of bytes read=241985830
    		HDFS: Number of bytes written=162
    		HDFS: Number of read operations=11
    		HDFS: Number of large read operations=0
    		HDFS: Number of write operations=2
    		HDFS: Number of bytes read erasure-coded=0
    	Job Counters 
    		Launched map tasks=2
    		Launched reduce tasks=1
    		Data-local map tasks=1
    		Rack-local map tasks=1
    		Total time spent by all maps in occupied slots (ms)=6063
    		Total time spent by all reduces in occupied slots (ms)=2213
    		Total time spent by all map tasks (ms)=6063
    		Total time spent by all reduce tasks (ms)=2213
    		Total vcore-milliseconds taken by all map tasks=6063
    		Total vcore-milliseconds taken by all reduce tasks=2213
    		Total megabyte-milliseconds taken by all map tasks=6208512
    		Total megabyte-milliseconds taken by all reduce tasks=2266112
    	Map-Reduce Framework
    		Map input records=1000000
    		Map output records=1000000
    		Map output bytes=16398590
    		Map output materialized bytes=18398602
    		Input split bytes=196
    		Combine input records=0
    		Combine output records=0
    		Reduce input groups=5
    		Reduce shuffle bytes=18398602
    		Reduce input records=1000000
    		Reduce output records=5
    		Spilled Records=2000000
    		Shuffled Maps =2
    		Failed Shuffles=0
    		Merged Map outputs=2
    		GC time elapsed (ms)=138
    		CPU time spent (ms)=4780
    		Physical memory (bytes) snapshot=907776000
    		Virtual memory (bytes) snapshot=7850885120
    		Total committed heap usage (bytes)=958922752
    		Peak Map Physical memory (bytes)=286842880
    		Peak Map Virtual memory (bytes)=2614874112
    		Peak Reduce Physical memory (bytes)=339152896
    		Peak Reduce Virtual memory (bytes)=2624278528
    	Shuffle Errors
    		BAD_ID=0
    		CONNECTION=0
    		IO_ERROR=0
    		WRONG_LENGTH=0
    		WRONG_MAP=0
    		WRONG_REDUCE=0
    	File Input Format Counters 
    		Bytes Read=241985634
    	File Output Format Counters 
    		Bytes Written=162
    2025-12-16 16:09:38,109 INFO streaming.StreamJob: Output directory: /log6



```python
!hdfs dfs -cat /log6/part-00000
```

    /usr	85657	114726	57.25%
    /usr/admin	85229	113867	57.19%
    /usr/admin/developer	85899	114101	57.05%
    /usr/login	85478	114747	57.31%
    /usr/register	85899	114397	57.11%

