------------- ESPECIALIZACIÓN EN INTELIGENCIA ARTIFICIAL Y BIG DATA -------------
---------------------------------------------------------------------------------

Módulo:                     BIG DATA APLICADO

Profesor:                   Víctor J. González

Unidad de Trabajo:          UT02. HDFS. Almacenamiento distribuido

Práctica:                   PR0201. MapReduce (I)

Resultados de aprendizaje:  RA1

# PR0401: MapReduce (I)

## Objetivo

Implementa un trabajo (job) de MapReduce utilizando Python para procesar una gran obra literaria y obtener un recuento detallado de la frecuencia de cada palabra. El objetivo es ir más allá del simple conteo, aplicando limpieza y normalización de datos, un paso fundamental en el procesamiento de texto.

El problema de “contar palabras” (Word Count) es el “Hola, Mundo” del paradigma MapReduce. Sin embargo, en un escenario real, los datos de texto (como libros, artículos o logs) están “sucios”. Contienen mayúsculas, minúsculas, signos de puntuación y palabras comunes que pueden distorsionar un análisis simple.

En esta práctica, analizarás el texto completo de “El ingenioso hidalgo don Quijote de la Mancha” para descubrir qué palabras utilizaba más Cervantes.

### Ejercicio 1

Tienes que implementar lo siguiente:

1. Fichero de Entrada (Input):

Un único fichero de texto (quijote.txt) que contiene la obra completa.

2. Fase MAP (Mapper):

El mapper debe leer el fichero línea por línea y realizar las siguientes tareas de normalización antes de emitir los pares clave-valor:

Conversión a minúsculas: todas las palabras deben ser convertidas a minúsculas para que “Caballero” y “caballero” cuenten como la misma palabra.
Eliminación de puntuación: se deben eliminar todos los signos de puntuación (comas, puntos, punto y coma, interrogaciones, etc.). Por ejemplo, “aventura!” debe tratarse como “aventura”.
División (tokenización): la línea limpia debe dividirse en palabras individuales (tokens).
Emisión: por cada palabra válida (token), el mapper debe emitir un par (palabra, 1).

3. Fase REDUCE (Reducer):

El reducer recibirá una palabra (clave) y una lista de ‘1’s (valores) asociados a esa palabra.

Agregación: debe sumar todos los valores (los ‘1’s) para obtener el conteo total de esa palabra específica.
Emisión: debe emitir el par final (palabra, conteo_total).

4. Fichero de Salida (Output):

El resultado final debe ser un fichero en formato CSV donde cada línea contenga una palabra y su número total de ocurrencias.


# Ejemplo de salida esperada:
...
hidalgo, 520
hizo, 310
hombre, 450
...


```python
!head -n 8 quijote.txt
```

    DON QUIJOTE DE LA MANCHA
    Miguel de Cervantes Saavedra
    
    PRIMERA PARTE
    CAPÍTULO 1: Que trata de la condición y ejercicio del famoso hidalgo D. Quijote de la Mancha
    En un lugar de la Mancha, de cuyo nombre no quiero acordarme, no ha mucho tiempo que vivía un hidalgo de los de lanza en astillero, adarga antigua, rocín flaco y galgo corredor. Una olla de algo más vaca que carnero, salpicón las más noches, duelos y quebrantos los sábados, lentejas los viernes, algún palomino de añadidura los domingos, consumían las tres partes de su hacienda. El resto della concluían sayo de velarte, calzas de velludo para las fiestas con sus pantuflos de lo mismo, los días de entre semana se honraba con su vellori de lo más fino. Tenía en su casa una ama que pasaba de los cuarenta, y una sobrina que no llegaba a los veinte, y un mozo de campo y plaza, que así ensillaba el rocín como tomaba la podadera. Frisaba la edad de nuestro hidalgo con los cincuenta años, era de complexión recia, seco de carnes, enjuto de rostro; gran madrugador y amigo de la caza. Quieren decir que tenía el sobrenombre de Quijada o Quesada (que en esto hay alguna diferencia en los autores que deste caso escriben), aunque por conjeturas verosímiles se deja entender que se llama Quijana; pero esto importa poco a nuestro cuento; basta que en la narración dél no se salga un punto de la verdad. Es, pues, de saber, que este sobredicho hidalgo, los ratos que estaba ocioso (que eran los más del año) se daba a leer libros de caballerías con tanta afición y gusto, que olvidó casi de todo punto el ejercicio de la caza, y aun la administración de su hacienda; y llegó a tanto su curiosidad y desatino en esto, que vendió muchas hanegas de tierra de sembradura, para comprar libros de caballerías en que leer; y así llevó a su casa todos cuantos pudo haber dellos; y de todos ningunos le parecían tan bien como los que compuso el famoso Feliciano de Silva: porque la claridad de su prosa, y aquellas intrincadas razones suyas, le parecían de perlas; y más cuando llegaba a leer aquellos requiebros y cartas de desafío, donde en muchas partes hallaba escrito: la razón de la sinrazón que a mi razón se hace, de tal manera mi razón enflaquece, que con razón me quejo de la vuestra fermosura, y también cuando leía: los altos cielos que de vuestra divinidad divinamente con las estrellas se fortifican, y os hacen merecedora del merecimiento que merece la vuestra grandeza. Con estas y semejantes razones perdía el pobre caballero el juicio, y desvelábase por entenderlas, y desentrañarles el sentido, que no se lo sacara, ni las entendiera el mismo Aristóteles, si resucitara para sólo ello. No estaba muy bien con las heridas que don Belianis daba y recibía, porque se imaginaba que por grandes maestros que le hubiesen curado, no dejaría de tener el rostro y todo el cuerpo lleno de cicatrices y señales; pero con todo alababa en su autor aquel acabar su libro con la promesa de aquella inacabable aventura, y muchas veces le vino deseo de tomar la pluma, y darle fin al pie de la letra como allí se promete; y sin duda alguna lo hiciera, y aun saliera con ello, si otros mayores y continuos pensamientos no se lo estorbaran.
    Tuvo muchas veces competencia con el cura de su lugar (que era hombre docto graduado en Sigüenza), sobre cuál había sido mejor caballero, Palmerín de Inglaterra o Amadís de Gaula; mas maese Nicolás, barbero del mismo pueblo, decía que ninguno llegaba al caballero del Febo, y que si alguno se le podía comparar, era don Galaor, hermano de Amadís de Gaula, porque tenía muy acomodada condición para todo; que no era caballero melindroso, ni tan llorón como su hermano, y que en lo de la valentía no le iba en zaga.
    En resolución, él se enfrascó tanto en su lectura, que se le pasaban las noches leyendo de claro en claro, y los días de turbio en turbio, y así, del poco dormir y del mucho leer, se le secó el cerebro, de manera que vino a perder el juicio. Llenósele la fantasía de todo aquello que leía en los libros, así de encantamientos, como de pendencias, batallas, desafíos, heridas, requiebros, amores, tormentas y disparates imposibles, y asentósele de tal modo en la imaginación que era verdad toda aquella máquina de aquellas soñadas invenciones que leía, que para él no había otra


Subimos el archivo a HDFS


```python
!hdfs dfs -put /media/notebooks/quijote.txt /practica_401
```


```python
!hdfs dfs -ls /practica_401

```

    Found 1 items
    -rw-r--r--   3 root supergroup     923119 2025-11-26 15:30 /practica_401/quijote.txt



```python
!hdfs dfs -head /practica_401/quijote.txt
```

    DON QUIJOTE DE LA MANCHA
    Miguel de Cervantes Saavedra
    
    PRIMERA PARTE
    CAPÍTULO 1: Que trata de la condición y ejercicio del famoso hidalgo D. Quijote de la Mancha
    En un lugar de la Mancha, de cuyo nombre no quiero acordarme, no ha mucho tiempo que vivía un hidalgo de los de lanza en astillero, adarga antigua, rocín flaco y galgo corredor. Una olla de algo más vaca que carnero, salpicón las más noches, duelos y quebrantos los sábados, lentejas los viernes, algún palomino de añadidura los domingos, consumían las tres partes de su hacienda. El resto della concluían sayo de velarte, calzas de velludo para las fiestas con sus pantuflos de lo mismo, los días de entre semana se honraba con su vellori de lo más fino. Tenía en su casa una ama que pasaba de los cuarenta, y una sobrina que no llegaba a los veinte, y un mozo de campo y plaza, que así ensillaba el rocín como tomaba la podadera. Frisaba la edad de nuestro hidalgo con los cincuenta años, era de complexión recia, sec


```python
%%writefile mapperQuijote.py
#!/usr/bin/env python3

import sys

lista = ["¿", "?", "¡", "!", ".", ",", ";", ":", "(", ")", '"', "'", "-"]

for line in sys.stdin:

    line = line.strip()
    for char in lista:
        line = line.replace(char, "")
    words = line.split()

    for word in words:
        print(f"{word.lower()}\t1")


```

    Overwriting mapperQuijote.py



```python
%%writefile reducerQuijote.py
#!/usr/bin/env python3

import sys

palabra = None
contador = 0
for line in sys.stdin:
    line = line.strip()
    clave, valor = line.split()
    valor = int(valor)

    if palabra is None:
        palabra = clave
        contador = valor
    if clave == palabra:
        contador += valor
    else:
        print(f"{palabra},{contador}")
        palabra = clave
        contador = valor

# Última línea
if palabra is not None:
    print(f"{palabra},{contador}")


```

    Overwriting reducerQuijote.py


Comprobamos el funcionamiento del mapper y del reducer


```python
# Simulamos para ver si funciona los scripts creados (El sort simula el shuffle)
!head -n 2 quijote.txt | python3 mapperQuijote.py | sort | python3 reducerQuijote.py
```

    cervantes,2
    de,2
    don,1
    la,1
    mancha,1
    miguel,1
    quijote,1
    saavedra,1


Lo ejecutamos en Streaming


```python
!hadoop jar \
/usr/local/hadoop/share/hadoop/tools/lib/hadoop-streaming-3.4.0.jar \
-file mapperQuijote.py \
-file reducerQuijote.py \
-mapper mapperQuijote.py \
-reducer reducerQuijote.py \
-input /practica_401/quijote.txt \
-output /Quijote
```

    2025-11-26 16:43:35,234 WARN streaming.StreamJob: -file option is deprecated, please use generic option -files instead.
    packageJobJar: [mapperQuijote.py, reducerQuijote.py, /tmp/hadoop-unjar6036516431191215711/] [] /tmp/streamjob4649945299550722737.jar tmpDir=null
    2025-11-26 16:43:35,737 INFO client.DefaultNoHARMFailoverProxyProvider: Connecting to ResourceManager at yarnmanager/172.19.0.6:8032
    2025-11-26 16:43:35,814 INFO client.DefaultNoHARMFailoverProxyProvider: Connecting to ResourceManager at yarnmanager/172.19.0.6:8032
    2025-11-26 16:43:36,066 INFO mapreduce.JobResourceUploader: Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/root/.staging/job_1764170116712_0001
    2025-11-26 16:43:36,456 INFO mapred.FileInputFormat: Total input files to process : 1
    2025-11-26 16:43:36,510 INFO mapreduce.JobSubmitter: number of splits:2
    2025-11-26 16:43:36,599 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1764170116712_0001
    2025-11-26 16:43:36,599 INFO mapreduce.JobSubmitter: Executing with tokens: []
    2025-11-26 16:43:36,705 INFO conf.Configuration: resource-types.xml not found
    2025-11-26 16:43:36,705 INFO resource.ResourceUtils: Unable to find 'resource-types.xml'.
    2025-11-26 16:43:37,143 INFO impl.YarnClientImpl: Submitted application application_1764170116712_0001
    2025-11-26 16:43:37,170 INFO mapreduce.Job: The url to track the job: http://yarnmanager:8088/proxy/application_1764170116712_0001/
    2025-11-26 16:43:37,171 INFO mapreduce.Job: Running job: job_1764170116712_0001
    2025-11-26 16:43:42,236 INFO mapreduce.Job: Job job_1764170116712_0001 running in uber mode : false
    2025-11-26 16:43:42,237 INFO mapreduce.Job:  map 0% reduce 0%
    2025-11-26 16:43:46,277 INFO mapreduce.Job:  map 100% reduce 0%
    2025-11-26 16:43:50,308 INFO mapreduce.Job:  map 100% reduce 100%
    2025-11-26 16:43:50,322 INFO mapreduce.Job: Job job_1764170116712_0001 completed successfully
    2025-11-26 16:43:50,372 INFO mapreduce.Job: Counters: 54
    	File System Counters
    		FILE: Number of bytes read=1547451
    		FILE: Number of bytes written=4037369
    		FILE: Number of read operations=0
    		FILE: Number of large read operations=0
    		FILE: Number of write operations=0
    		HDFS: Number of bytes read=927409
    		HDFS: Number of bytes written=163892
    		HDFS: Number of read operations=11
    		HDFS: Number of large read operations=0
    		HDFS: Number of write operations=2
    		HDFS: Number of bytes read erasure-coded=0
    	Job Counters 
    		Launched map tasks=2
    		Launched reduce tasks=1
    		Data-local map tasks=2
    		Total time spent by all maps in occupied slots (ms)=3947
    		Total time spent by all reduces in occupied slots (ms)=1368
    		Total time spent by all map tasks (ms)=3947
    		Total time spent by all reduce tasks (ms)=1368
    		Total vcore-milliseconds taken by all map tasks=3947
    		Total vcore-milliseconds taken by all reduce tasks=1368
    		Total megabyte-milliseconds taken by all map tasks=4041728
    		Total megabyte-milliseconds taken by all reduce tasks=1400832
    	Map-Reduce Framework
    		Map input records=1848
    		Map output records=162862
    		Map output bytes=1221721
    		Map output materialized bytes=1547457
    		Input split bytes=194
    		Combine input records=0
    		Combine output records=0
    		Reduce input groups=13457
    		Reduce shuffle bytes=1547457
    		Reduce input records=162862
    		Reduce output records=13457
    		Spilled Records=325724
    		Shuffled Maps =2
    		Failed Shuffles=0
    		Merged Map outputs=2
    		GC time elapsed (ms)=151
    		CPU time spent (ms)=2670
    		Physical memory (bytes) snapshot=856162304
    		Virtual memory (bytes) snapshot=7851458560
    		Total committed heap usage (bytes)=983564288
    		Peak Map Physical memory (bytes)=283213824
    		Peak Map Virtual memory (bytes)=2614046720
    		Peak Reduce Physical memory (bytes)=294580224
    		Peak Reduce Virtual memory (bytes)=2624638976
    	Shuffle Errors
    		BAD_ID=0
    		CONNECTION=0
    		IO_ERROR=0
    		WRONG_LENGTH=0
    		WRONG_MAP=0
    		WRONG_REDUCE=0
    	File Input Format Counters 
    		Bytes Read=927215
    	File Output Format Counters 
    		Bytes Written=163892
    2025-11-26 16:43:50,372 INFO streaming.StreamJob: Output directory: /Quijote



```python
!hdfs dfs -head  /Quijote/part-00000
```

## Ejercicio 2: Filtrado de palabras representativas

En este ejercicio tienes que:

Crear una lista (o carga desde un fichero) de palabras no significativas comunes en español (ej. “de”, “la”, “el”, “y”, “en”, “que”, “a”, “los”, “del”, “se”).

Modificra el mapper para que no emita ningún par clave-valor si la palabra se encuentra en tu lista de palabras no significativas.

El resultado final será un conteo de palabras significativas, excluyendo las más comunes y menos informativas.

NOTA: si optas por cargar la lista de palabras comunes desde un fichero, éste se deberá ubicar en el sistema de ficheros local y tendrás que referenciarlo mediante el parámetro -file (de forma análoga a como haces con mapper.py y reducer-.py) para que Hadoop lo inyecte a cada uno de los nodos en que se ejecute el mapper. Una vez hecho esto, desde dentro del código Python simplemente debes referenciarlo por su nombre.


```python
%%writefile mapperQuijote2.py
#!/usr/bin/env python3

import sys
lista2 = ["de", "la", "el", "y", "en", "que", "a", "los", "del", "se"]
lista = ["¿", "?", "¡", "!", ".", ",", ";", ":", "(", ")", '"', "'", "-",]
lista_aux = []
for line in sys.stdin:

    line = line.strip()
    for char in lista:
        line = line.replace(char, "")
    words = line.split()
    lista_aux = []
    for palabra in words:
        if palabra.lower() not in lista2:
            lista_aux.append(palabra.lower())

    for palabrasLista in lista_aux:
        print(f"{palabrasLista.lower()}\t1")


```

    Overwriting mapperQuijote2.py



```python
%%writefile reducerQuijote2.py
#!/usr/bin/env python3

import sys

palabra = None
contador = 0
for line in sys.stdin:
    line = line.strip()
    clave, valor = line.split("\t")
    valor = int(valor)

    if palabra is None:
        palabra = clave
        contador = valor
    if clave == palabra:
        contador += valor
    else:
        print(f"{palabra},{contador}")
        palabra = clave
        contador = valor

# Última línea
if palabra is not None:
    print(f"{palabra},{contador}")

```

    Overwriting reducerQuijote2.py


Comprobamos


```python
!head -n 2 quijote.txt | python3 mapperQuijote2.py | sort | python3 reducerQuijote2.py
```

    cervantes,2
    don,1
    mancha,1
    miguel,1
    quijote,1
    saavedra,1


Una vez comprobado lo ejecutamos en Streaming


```python
!hadoop jar \
/usr/local/hadoop/share/hadoop/tools/lib/hadoop-streaming-3.4.0.jar \
-file mapperQuijote2.py \
-file reducerQuijote2.py \
-mapper mapperQuijote2.py \
-reducer reducerQuijote2.py \
-input /practica_401/quijote.txt \
-output /Quijote2
```

    2025-11-26 18:18:36,361 WARN streaming.StreamJob: -file option is deprecated, please use generic option -files instead.
    packageJobJar: [mapperQuijote2.py, reducerQuijote2.py, /tmp/hadoop-unjar6231300534071858939/] [] /tmp/streamjob6755370686071516765.jar tmpDir=null
    2025-11-26 18:18:36,869 INFO client.DefaultNoHARMFailoverProxyProvider: Connecting to ResourceManager at yarnmanager/172.19.0.6:8032
    2025-11-26 18:18:36,941 INFO client.DefaultNoHARMFailoverProxyProvider: Connecting to ResourceManager at yarnmanager/172.19.0.6:8032
    2025-11-26 18:18:37,083 INFO mapreduce.JobResourceUploader: Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/root/.staging/job_1764170116712_0007
    2025-11-26 18:18:37,361 INFO mapred.FileInputFormat: Total input files to process : 1
    2025-11-26 18:18:37,417 INFO mapreduce.JobSubmitter: number of splits:2
    2025-11-26 18:18:37,480 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1764170116712_0007
    2025-11-26 18:18:37,480 INFO mapreduce.JobSubmitter: Executing with tokens: []
    2025-11-26 18:18:37,585 INFO conf.Configuration: resource-types.xml not found
    2025-11-26 18:18:37,585 INFO resource.ResourceUtils: Unable to find 'resource-types.xml'.
    2025-11-26 18:18:37,636 INFO impl.YarnClientImpl: Submitted application application_1764170116712_0007
    2025-11-26 18:18:37,662 INFO mapreduce.Job: The url to track the job: http://yarnmanager:8088/proxy/application_1764170116712_0007/
    2025-11-26 18:18:37,663 INFO mapreduce.Job: Running job: job_1764170116712_0007
    2025-11-26 18:18:41,717 INFO mapreduce.Job: Job job_1764170116712_0007 running in uber mode : false
    2025-11-26 18:18:41,719 INFO mapreduce.Job:  map 0% reduce 0%
    2025-11-26 18:18:44,772 INFO mapreduce.Job:  map 100% reduce 0%
    2025-11-26 18:18:48,795 INFO mapreduce.Job:  map 100% reduce 100%
    2025-11-26 18:18:48,803 INFO mapreduce.Job: Job job_1764170116712_0007 completed successfully
    2025-11-26 18:18:48,853 INFO mapreduce.Job: Counters: 54
    	File System Counters
    		FILE: Number of bytes read=1232639
    		FILE: Number of bytes written=3407772
    		FILE: Number of read operations=0
    		FILE: Number of large read operations=0
    		FILE: Number of write operations=0
    		HDFS: Number of bytes read=927409
    		HDFS: Number of bytes written=163802
    		HDFS: Number of read operations=11
    		HDFS: Number of large read operations=0
    		HDFS: Number of write operations=2
    		HDFS: Number of bytes read erasure-coded=0
    	Job Counters 
    		Launched map tasks=2
    		Launched reduce tasks=1
    		Data-local map tasks=2
    		Total time spent by all maps in occupied slots (ms)=2758
    		Total time spent by all reduces in occupied slots (ms)=1336
    		Total time spent by all map tasks (ms)=2758
    		Total time spent by all reduce tasks (ms)=1336
    		Total vcore-milliseconds taken by all map tasks=2758
    		Total vcore-milliseconds taken by all reduce tasks=1336
    		Total megabyte-milliseconds taken by all map tasks=2824192
    		Total megabyte-milliseconds taken by all reduce tasks=1368064
    	Map-Reduce Framework
    		Map input records=1848
    		Map output records=117949
    		Map output bytes=996735
    		Map output materialized bytes=1232645
    		Input split bytes=194
    		Combine input records=0
    		Combine output records=0
    		Reduce input groups=13447
    		Reduce shuffle bytes=1232645
    		Reduce input records=117949
    		Reduce output records=13447
    		Spilled Records=235898
    		Shuffled Maps =2
    		Failed Shuffles=0
    		Merged Map outputs=2
    		GC time elapsed (ms)=120
    		CPU time spent (ms)=2430
    		Physical memory (bytes) snapshot=854683648
    		Virtual memory (bytes) snapshot=7850332160
    		Total committed heap usage (bytes)=961544192
    		Peak Map Physical memory (bytes)=284327936
    		Peak Map Virtual memory (bytes)=2612846592
    		Peak Reduce Physical memory (bytes)=290955264
    		Peak Reduce Virtual memory (bytes)=2625531904
    	Shuffle Errors
    		BAD_ID=0
    		CONNECTION=0
    		IO_ERROR=0
    		WRONG_LENGTH=0
    		WRONG_MAP=0
    		WRONG_REDUCE=0
    	File Input Format Counters 
    		Bytes Read=927215
    	File Output Format Counters 
    		Bytes Written=163802
    2025-11-26 18:18:48,853 INFO streaming.StreamJob: Output directory: /Quijote2


Comprobamos que se han creado los archivos **succes** y **part-00000**


```python
!hdfs dfs -ls /Quijote2
```

    Found 2 items
    -rw-r--r--   3 root supergroup          0 2025-11-26 18:18 /Quijote2/_SUCCESS
    -rw-r--r--   3 root supergroup     163802 2025-11-26 18:18 /Quijote2/part-00000



```python
!hdfs dfs -head /Quijote2/part-00000
```

    1,2	
    10,1	
    11,1	
    12,1	
    13,1	
    14,1	
    15,1	
    16,1	
    17,1	
    18,1	
    19,1	
    2,1	
    20,1	
    21,1	
    22,1	
    23,1	
    24,1	
    25,1	
    26,1	
    27,1	
    28,1	
    29,1	
    3,1	
    30,2	
    31,1	
    32,1	
    33,1	
    34,1	
    35,1	
    36,1	
    37,1	
    38,1	
    39,1	
    4,1	
    40,1	
    41,1	
    42,1	
    43,1	
    44,1	
    45,1	
    5,1	
    6,1	
    7,1	
    8,1	
    9,1	
    [él],1	
    [no],1	
    aa,1	
    abad,1	
    abadejo,2	
    abades,1	
    abajarse,2	
    abajen,1	
    abajo,21	
    abajó,1	
    abalanza,1	
    abalánzase,1	
    abandonarme,1	
    abatanar,1	
    abecé,3	
    abejas,1	
    abencerraje,1	
    abierta,3	
    abiertas,1	
    abierto,7	
    abiertos,5	
    abindarráez,3	
    abismo,2	
    ablandaba,1	
    ablande,1	
    ablandó,1	
    abollada,1	
    abollado,1	
    aborrascadas,1	
    aborrece,2	
    aborrece»,1	
    aborrecida,1	
    aborrecido,3	
    aborrecimiento,2	
    aborreció,1	
    aborrecí,1	
    aborrezco,3	
    abra,2	
    abracé,1	
    abran,3	
    abrasa,1	
    abrasada,1	
    abrasados,2	
    abrasar,1	
    abrasó,2	
    abrazada,5	
    abrazado,4	
    abrazamiento,1	
    abrazando,2	
    abrazar,9	
    abrazara,1	
    abrazará,1	
    abrazarle,1	
    abrazase,1	
    abrazándole,4	
    abrazándonos,1	
    abrazándose,1	
    abrazáronse,2	
    abrazo,1	
    abrazos,1	
    abrazó,7	
    abrazó

## Ejercicio 3: Ordenación por Frecuencia (Top-N)

En este último ejercicio debes:

Implementar un segundo trabajo de MapReduce que tome la salida del primero.

Este segundo trabajo debe reordenar los datos para que la salida final esté ordenada por frecuencia de forma ascendente, mostrando las palabras más usadas primero.

Tienes que aprovecharte de que Hadoop se encarga de ordenar por la clave, así que en el mapper del segundo trabajo deberías invertir el par (clave, valor) para que sea (valor, clave)

NOTA: en este ejercicio no es necesario el reducer, ya que todo el trabajo se realizará en el mapper y en el shuffle. Si quieres omitir el reducer al ejecutar Hadoop Streaming debes utilizar el parámetro *-D mapreduce.job.reduces=0*



```python
%%writefile mapperQuijote3.py
#!/usr/bin/env python3
import sys

for line in sys.stdin:
    for word in line.strip().split():
        clean_word = ""
        for char in word:
            if char.isalpha():
                clean_word += char

        if clean_word:
            print(f"{clean_word}\t1")



```

    Overwriting mapperQuijote3.py



```python
!head -n 1 quijote.txt | python3 mapperQuijote3.py 
```

    DON	1
    QUIJOTE	1
    DE	1
    LA	1
    MANCHA	1



```python
%%writefile mapperQuijote3_2.py
#!/usr/bin/env python3
import sys

word_dict = {}

for line in sys.stdin:
    line = line.strip()
    clave, valor = line.split("\t")
    valor = int(valor)

    if clave not in word_dict:
        word_dict[clave] = valor
    else:
        word_dict[clave] += valor

for key, value in sorted(word_dict.items(), key=lambda x: x[1], reverse=True):
    print(f"{value}\t{key}")


```

    Overwriting mapperQuijote3_2.py



```python
!head -n 2 quijote.txt | python3 mapperQuijote3.py |  python3 mapperQuijote3_2.py
```

    1	DON
    1	QUIJOTE
    1	DE
    1	LA
    1	MANCHA
    1	Miguel
    1	de
    1	Cervantes
    1	Saavedra


Hacemos el Primer **mapper**


```python
!hadoop jar \
/usr/local/hadoop/share/hadoop/tools/lib/hadoop-streaming-3.4.0.jar \
-D mapreduce.job.reduces=0 \
-file mapperQuijote3.py \
-mapper mapperQuijote3.py \
-input /practica_401/quijote.txt \
-output /Quijote3
```

    2025-11-27 18:03:04,426 WARN streaming.StreamJob: -file option is deprecated, please use generic option -files instead.
    packageJobJar: [mapperQuijote3.py, /tmp/hadoop-unjar7548932980379788989/] [] /tmp/streamjob1920225721542383207.jar tmpDir=null
    2025-11-27 18:03:04,895 INFO client.DefaultNoHARMFailoverProxyProvider: Connecting to ResourceManager at yarnmanager/172.19.0.6:8032
    2025-11-27 18:03:04,974 INFO client.DefaultNoHARMFailoverProxyProvider: Connecting to ResourceManager at yarnmanager/172.19.0.6:8032
    2025-11-27 18:03:05,110 INFO mapreduce.JobResourceUploader: Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/root/.staging/job_1764264263707_0003
    2025-11-27 18:03:05,333 INFO mapred.FileInputFormat: Total input files to process : 1
    2025-11-27 18:03:05,387 INFO mapreduce.JobSubmitter: number of splits:2
    2025-11-27 18:03:05,459 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1764264263707_0003
    2025-11-27 18:03:05,459 INFO mapreduce.JobSubmitter: Executing with tokens: []
    2025-11-27 18:03:05,566 INFO conf.Configuration: resource-types.xml not found
    2025-11-27 18:03:05,566 INFO resource.ResourceUtils: Unable to find 'resource-types.xml'.
    2025-11-27 18:03:05,605 INFO impl.YarnClientImpl: Submitted application application_1764264263707_0003
    2025-11-27 18:03:05,626 INFO mapreduce.Job: The url to track the job: http://yarnmanager:8088/proxy/application_1764264263707_0003/
    2025-11-27 18:03:05,626 INFO mapreduce.Job: Running job: job_1764264263707_0003
    2025-11-27 18:03:10,672 INFO mapreduce.Job: Job job_1764264263707_0003 running in uber mode : false
    2025-11-27 18:03:10,672 INFO mapreduce.Job:  map 0% reduce 0%
    2025-11-27 18:03:15,419 INFO mapreduce.Job:  map 100% reduce 0%
    2025-11-27 18:03:17,448 INFO mapreduce.Job: Job job_1764264263707_0003 completed successfully
    2025-11-27 18:03:17,497 INFO mapreduce.Job: Counters: 33
    	File System Counters
    		FILE: Number of bytes read=0
    		FILE: Number of bytes written=626978
    		FILE: Number of read operations=0
    		FILE: Number of large read operations=0
    		FILE: Number of write operations=0
    		HDFS: Number of bytes read=927409
    		HDFS: Number of bytes written=1184537
    		HDFS: Number of read operations=14
    		HDFS: Number of large read operations=0
    		HDFS: Number of write operations=4
    		HDFS: Number of bytes read erasure-coded=0
    	Job Counters 
    		Launched map tasks=2
    		Data-local map tasks=2
    		Total time spent by all maps in occupied slots (ms)=8327
    		Total time spent by all reduces in occupied slots (ms)=0
    		Total time spent by all map tasks (ms)=8327
    		Total vcore-milliseconds taken by all map tasks=8327
    		Total megabyte-milliseconds taken by all map tasks=8526848
    	Map-Reduce Framework
    		Map input records=1848
    		Map output records=162815
    		Input split bytes=194
    		Spilled Records=0
    		Failed Shuffles=0
    		Merged Map outputs=0
    		GC time elapsed (ms)=99
    		CPU time spent (ms)=1480
    		Physical memory (bytes) snapshot=542760960
    		Virtual memory (bytes) snapshot=5234380800
    		Total committed heap usage (bytes)=645398528
    		Peak Map Physical memory (bytes)=274382848
    		Peak Map Virtual memory (bytes)=2617802752
    	File Input Format Counters 
    		Bytes Read=927215
    	File Output Format Counters 
    		Bytes Written=1184537
    2025-11-27 18:03:17,497 INFO streaming.StreamJob: Output directory: /Quijote3



```python
!hdfs dfs -head /Quijote3/part-00000
```

    Cardenio	1
    de	1
    boda	1
    estoy	1
    vestida	1
    ya	1
    me	1
    estan	1
    aguardando	1
    en	1
    la	1
    sala	1
    don	1
    Femando	1
    el	1
    traidor	1
    y	1
    mi	1
    padre	1
    el	1
    codicioso	1
    con	1
    otros	1
    testigos	1
    que	1
    antes	1
    lo	1
    seran	1
    de	1
    mi	1
    muerte	1
    que	1
    de	1
    mi	1
    desposorio	1
    No	1
    te	1
    turbes	1
    amigo	1
    sino	1
    procura	1
    hallade	1
    presente	1
    a	1
    este	1
    sacrificio	1
    el	1
    cual	1
    si	1
    no	1
    pudiese	1
    ser	1
    estorbado	1
    de	1
    mis	1
    razones	1
    una	1
    daga	1
    llevo	1
    escondida	1
    que	1
    podra	1
    estorbar	1
    mas	1
    determinadas	1
    fuerzas	1
    dando	1
    fin	1
    a	1
    mi	1
    vida	1
    y	1
    principio	1
    a	1
    que	1
    conozcas	1
    la	1
    voluntad	1
    que	1
    te	1
    he	1
    tenido	1
    y	1
    tengo	1
    Yo	1
    le	1
    respondi	1
    turbado	1
    y	1
    apriesa	1
    temeroso	1
    no	1
    me	1
    faltase	1
    lugar	1
    para	1
    responderla	1
    Hagan	1
    senora	1
    tus	1
    obras	1
    verdaderas	1
    tus	1
    palabras	1
    que	1
    si	1
    tu	1
    llevas	1
    daga	1
    para	1
    acreditarte	1
    aqui	1
    llevo	1
    yo	1
    espada	1
    para	1
    defenderte	1
    con	1
    ella	1
    o	1
    para	1
    matarme	1
    si	1
    la	1
    suerte	1
    nos	1
    fuere	1
    contraria	1
    No	1
    creo	1
    que	1
    pudo	1
    oir	1
    todas	1
    estas	1
    razones

Hacemos el Segundo **mapper**


```python
!hadoop jar \
/usr/local/hadoop/share/hadoop/tools/lib/hadoop-streaming-3.4.0.jar \
-D mapreduce.job.reduces=0 \
-file mapperQuijote3_2.py \
-mapper mapperQuijote3_2.py \
-input /Quijote3/part-00000\
-output /Quijote3_2
```

    2025-11-27 18:06:33,384 WARN streaming.StreamJob: -file option is deprecated, please use generic option -files instead.
    packageJobJar: [mapperQuijote3_2.py, /tmp/hadoop-unjar4331178234957775398/] [] /tmp/streamjob6209179644146063497.jar tmpDir=null
    2025-11-27 18:06:33,886 INFO client.DefaultNoHARMFailoverProxyProvider: Connecting to ResourceManager at yarnmanager/172.19.0.6:8032
    2025-11-27 18:06:33,959 INFO client.DefaultNoHARMFailoverProxyProvider: Connecting to ResourceManager at yarnmanager/172.19.0.6:8032
    2025-11-27 18:06:34,098 INFO mapreduce.JobResourceUploader: Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/root/.staging/job_1764264263707_0005
    2025-11-27 18:06:34,310 INFO mapred.FileInputFormat: Total input files to process : 1
    2025-11-27 18:06:34,364 INFO mapreduce.JobSubmitter: number of splits:2
    2025-11-27 18:06:34,442 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1764264263707_0005
    2025-11-27 18:06:34,442 INFO mapreduce.JobSubmitter: Executing with tokens: []
    2025-11-27 18:06:34,559 INFO conf.Configuration: resource-types.xml not found
    2025-11-27 18:06:34,559 INFO resource.ResourceUtils: Unable to find 'resource-types.xml'.
    2025-11-27 18:06:34,611 INFO impl.YarnClientImpl: Submitted application application_1764264263707_0005
    2025-11-27 18:06:34,634 INFO mapreduce.Job: The url to track the job: http://yarnmanager:8088/proxy/application_1764264263707_0005/
    2025-11-27 18:06:34,635 INFO mapreduce.Job: Running job: job_1764264263707_0005
    2025-11-27 18:06:39,689 INFO mapreduce.Job: Job job_1764264263707_0005 running in uber mode : false
    2025-11-27 18:06:39,690 INFO mapreduce.Job:  map 0% reduce 0%
    2025-11-27 18:06:43,750 INFO mapreduce.Job:  map 100% reduce 0%
    2025-11-27 18:06:43,759 INFO mapreduce.Job: Job job_1764264263707_0005 completed successfully
    2025-11-27 18:06:43,804 INFO mapreduce.Job: Counters: 33
    	File System Counters
    		FILE: Number of bytes read=0
    		FILE: Number of bytes written=626988
    		FILE: Number of read operations=0
    		FILE: Number of large read operations=0
    		FILE: Number of write operations=0
    		HDFS: Number of bytes read=597218
    		HDFS: Number of bytes written=114569
    		HDFS: Number of read operations=14
    		HDFS: Number of large read operations=0
    		HDFS: Number of write operations=4
    		HDFS: Number of bytes read erasure-coded=0
    	Job Counters 
    		Launched map tasks=2
    		Data-local map tasks=2
    		Total time spent by all maps in occupied slots (ms)=2828
    		Total time spent by all reduces in occupied slots (ms)=0
    		Total time spent by all map tasks (ms)=2828
    		Total vcore-milliseconds taken by all map tasks=2828
    		Total megabyte-milliseconds taken by all map tasks=2895872
    	Map-Reduce Framework
    		Map input records=81705
    		Map output records=11126
    		Input split bytes=184
    		Spilled Records=0
    		Failed Shuffles=0
    		Merged Map outputs=0
    		GC time elapsed (ms)=79
    		CPU time spent (ms)=1500
    		Physical memory (bytes) snapshot=517009408
    		Virtual memory (bytes) snapshot=5235621888
    		Total committed heap usage (bytes)=553123840
    		Peak Map Physical memory (bytes)=273027072
    		Peak Map Virtual memory (bytes)=2619105280
    	File Input Format Counters 
    		Bytes Read=597034
    	File Output Format Counters 
    		Bytes Written=114569
    2025-11-27 18:06:43,804 INFO streaming.StreamJob: Output directory: /Quijote3_2



```python
!hdfs dfs -head /Quijote3_2/part-00000
```

    2566	que
    1838	de
    1743	y
    1065	la
    1019	a
    871	el
    861	en
    730	no
    539	se
    477	con
    447	por
    407	le
    401	lo
    394	su
    374	los
    353	me
    332	mi
    274	como
    253	si
    241	las
    234	yo
    231	dijo
    229	es
    227	mas
    212	tan
    210	para
    202	del
    179	un
    176	porque
    173	don
    164	habia
    156	sin
    153	ni
    151	al
    147	todo
    131	ser
    129	o
    128	Lotario
    126	una
    125	Camila
    124	ella
    117	ha
    114	Quijote
    113	Sancho
    110	te
    108	esto
    106	sus
    106	Y
    104	Anselmo
    103	era
    101	pues
    100	bien
    100	asi
    100	esta
    99	respondio
    98	vuestra
    97	cuando
    94	tu
    90	este
    81	senora
    79	cual
    79	donde
    77	merced
    76	quien
    76	cura
    76	hacer
    75	No
    74	decir
    72	ya
    71	he
    70	aquel
    69	dos
    68	senor
    66	mis
    64	cosa
    63	todos
    62	pero
    62	mal
    61	sino
    61	Dorotea
    60	amigo
    60	vida
    59	aun
    57	otro
    57	os
    57	aunque
    55	casa
    55	poco
    55	buena
    53	ahora
    53	fue
    53	cosas
    51	solo
    51	hasta
    51	tanto
    50	alli
    50	verdad
    49	luego
    49	otra
    48	alguna
    48	ver
    48	puesto
    47	lugar
    47	tiene
    45	antes
    44	aquella
    44	estaba
    43	aqui
    43	manera
    43	ellos
    43	dar
    42	Cardenio
    42	visto
    42	Pues
    42	dicho
    41	gusto
    41	tiempo
    41	tenia
    41	reino
    40	entre
    40	muy
    39
